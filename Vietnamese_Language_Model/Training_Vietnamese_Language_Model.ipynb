{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":132},"id":"5QbrZFvdGJZo","outputId":"d84d9684-6868-45d1-fb17-b3109e7a6556"},"outputs":[{"name":"stdout","output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"]}],"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bbRGOLPtHZwN"},"outputs":[],"source":["import pickle\n","\n","# def load_sequences(part):\n","#     with open('drive/My Drive/Machine_Learning-prj/vietnamese_language_model/data/sequences'+ str(part) + '.0', 'rb') as f:\n","#         sequences = pickle.load(f)\n","#     return sequences[:1000000]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wpvMVNCZHopX"},"outputs":[],"source":["# sequences = load_sequences(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-KEh80wHv8Y"},"outputs":[],"source":["# len(sequences)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dsJMBYU2HxtB"},"outputs":[],"source":["# import keras\n","\n","# tokenizer = keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^`{|}~ ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NvuZPG5dIKrG"},"outputs":[],"source":["# tokenizer.fit_on_texts(sequences)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ltmnbmD5ZHOf"},"outputs":[],"source":["# with open('drive/My Drive/Machine_Learning-prj/vietnamese_language_model/tokenizer_S1.pkl', 'wb') as f:\n","#     pickle.dump(tokenizer, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bR0UYclHQpPO"},"outputs":[],"source":["# sequences_digit = tokenizer.texts_to_sequences(sequences)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"26ff3gLIZT8R"},"outputs":[],"source":["# with open('drive/My Drive/Machine_Learning-prj/vietnamese_language_model/sequences_digit_S1.pkl', 'wb') as f:\n","#     pickle.dump(sequences_digit, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"unpJQ6ZWT3eX"},"outputs":[],"source":["#del sequences"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"cCQenKUvgp8M","outputId":"e806fa1f-b1b2-48e6-e238-8dddfa57d2e7"},"outputs":[{"name":"stderr","output_type":"stream","text":["Using TensorFlow backend.\n"]}],"source":[" with open('drive/My Drive/Machine_Learning-prj/vietnamese_language_model/tokenizer_S1.pkl', 'rb') as f:\n","    tokenizer = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pgowNLY6g7to"},"outputs":[],"source":["with open('drive/My Drive/Machine_Learning-prj/vietnamese_language_model/sequences_digit_S1.pkl', 'rb') as f:\n","    sequences_digit = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KoRLb80DQfcX"},"outputs":[],"source":["vocab_size = len(tokenizer.word_index) + 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iNOFV1pFbD9M"},"outputs":[],"source":["import numpy as np\n","\n","def data_generator(sequences_digit, batch_size):\n","    while True:\n","        batch_paths = np.random.choice(a = len(sequences_digit), size = batch_size)\n","        input = []\n","        output = []\n","        \n","        for i in batch_paths:\n","            input.append(sequences_digit[i][:-1])\n","            output.append(sequences_digit[i][-1])\n","        input = np.array(input)\n","        output = keras.utils.to_categorical(output, num_classes=vocab_size)\n","        output = np.array(output)\n","        \n","        yield (input, output)\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eqLgryZscNOr"},"outputs":[],"source":["from keras.models import Model, Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Activation, GRU, Dense, Input, Add, Concatenate, Reshape, Lambda, BatchNormalization, Dropout, Embedding, LSTM\n","from keras.optimizers import SGD, RMSprop\n","import keras"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":454},"id":"wBdeXfaWS7aS","outputId":"6a064449-cd23-4f0f-f74c-aecaf6dc3ab6"},"outputs":[{"name":"stdout","output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 50, 50)            1733100   \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 50, 50)            200       \n","_________________________________________________________________\n","lstm_3 (LSTM)                (None, 50, 512)           1153024   \n","_________________________________________________________________\n","lstm_4 (LSTM)                (None, 512)               2099200   \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 100)               51300     \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 100)               0         \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 100)               400       \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 34662)             3500862   \n","=================================================================\n","Total params: 8,538,086\n","Trainable params: 8,537,786\n","Non-trainable params: 300\n","_________________________________________________________________\n"]}],"source":["model = Sequential()\n","model.add(Embedding(vocab_size, 50, input_length=50))\n","model.add(BatchNormalization())\n","model.add(LSTM(512, return_sequences=True))\n","model.add(LSTM(512))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(BatchNormalization())\n","model.add(Dense(vocab_size, activation='softmax'))\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q_v-eg30cMZr"},"outputs":[],"source":["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"ZVgFPN4MSjYp","outputId":"a2b6d1ef-159c-433f-9d2c-0edf3d4a11c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading pre-trained weight\n"]}],"source":["from keras.models import load_model\n","\n","print(\"Loading pre-trained weight\")\n","model.load_weights('drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GXeW3lr4RcKs"},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint\n","\n","filepath = 'drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5'\n","checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dZHW5_UUdGs4"},"outputs":[],"source":["batch_size=512"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":4872},"id":"mIcqO6UWcsT_","outputId":"2409728b-5ace-4ed8-978d-22cace15c014"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","1953/1953 [==============================] - 744s 381ms/step - loss: 3.2499 - acc: 0.3510\n","\n","Epoch 00001: acc improved from -inf to 0.35099, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 2/100\n","1953/1953 [==============================] - 739s 379ms/step - loss: 3.2380 - acc: 0.3523\n","\n","Epoch 00002: acc improved from 0.35099 to 0.35228, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 3/100\n","1953/1953 [==============================] - 739s 378ms/step - loss: 3.2206 - acc: 0.3551\n","\n","Epoch 00003: acc improved from 0.35228 to 0.35511, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 4/100\n","1953/1953 [==============================] - 740s 379ms/step - loss: 3.2057 - acc: 0.3569\n","\n","Epoch 00004: acc improved from 0.35511 to 0.35693, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 5/100\n","1953/1953 [==============================] - 741s 379ms/step - loss: 3.1943 - acc: 0.3587\n","\n","Epoch 00005: acc improved from 0.35693 to 0.35871, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 6/100\n","1953/1953 [==============================] - 741s 379ms/step - loss: 3.1766 - acc: 0.3612\n","\n","Epoch 00006: acc improved from 0.35871 to 0.36115, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 7/100\n","1953/1953 [==============================] - 741s 379ms/step - loss: 3.1686 - acc: 0.3621\n","\n","Epoch 00007: acc improved from 0.36115 to 0.36209, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 8/100\n","1953/1953 [==============================] - 741s 379ms/step - loss: 3.1553 - acc: 0.3634\n","\n","Epoch 00008: acc improved from 0.36209 to 0.36341, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 9/100\n","1953/1953 [==============================] - 740s 379ms/step - loss: 3.1501 - acc: 0.3645\n","\n","Epoch 00009: acc improved from 0.36341 to 0.36449, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 10/100\n","1953/1953 [==============================] - 740s 379ms/step - loss: 3.1377 - acc: 0.3660\n","\n","Epoch 00010: acc improved from 0.36449 to 0.36600, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 11/100\n","1953/1953 [==============================] - 741s 379ms/step - loss: 3.1312 - acc: 0.3669\n","\n","Epoch 00011: acc improved from 0.36600 to 0.36686, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 12/100\n","1953/1953 [==============================] - 737s 378ms/step - loss: 3.1213 - acc: 0.3682\n","\n","Epoch 00012: acc improved from 0.36686 to 0.36817, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 13/100\n","1953/1953 [==============================] - 735s 376ms/step - loss: 3.1146 - acc: 0.3693\n","\n","Epoch 00013: acc improved from 0.36817 to 0.36925, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 14/100\n","1953/1953 [==============================] - 732s 375ms/step - loss: 3.1045 - acc: 0.3700\n","\n","Epoch 00014: acc improved from 0.36925 to 0.37003, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 15/100\n","1953/1953 [==============================] - 726s 372ms/step - loss: 3.1064 - acc: 0.3699\n","\n","Epoch 00015: acc did not improve from 0.37003\n","Epoch 16/100\n","1953/1953 [==============================] - 728s 373ms/step - loss: 3.0992 - acc: 0.3711\n","\n","Epoch 00016: acc improved from 0.37003 to 0.37111, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 17/100\n","1953/1953 [==============================] - 731s 374ms/step - loss: 3.0843 - acc: 0.3730\n","\n","Epoch 00017: acc improved from 0.37111 to 0.37296, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 18/100\n","1953/1953 [==============================] - 719s 368ms/step - loss: 3.0745 - acc: 0.3739\n","\n","Epoch 00018: acc improved from 0.37296 to 0.37393, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 19/100\n","1953/1953 [==============================] - 726s 372ms/step - loss: 3.0690 - acc: 0.3744\n","\n","Epoch 00019: acc improved from 0.37393 to 0.37443, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 20/100\n","1953/1953 [==============================] - 730s 374ms/step - loss: 3.0586 - acc: 0.3762\n","\n","Epoch 00020: acc improved from 0.37443 to 0.37622, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 21/100\n","1953/1953 [==============================] - 737s 377ms/step - loss: 3.0532 - acc: 0.3765\n","\n","Epoch 00021: acc improved from 0.37622 to 0.37650, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 22/100\n","1953/1953 [==============================] - 739s 379ms/step - loss: 3.0540 - acc: 0.3758\n","\n","Epoch 00022: acc did not improve from 0.37650\n","Epoch 23/100\n","1953/1953 [==============================] - 733s 375ms/step - loss: 3.0401 - acc: 0.3779\n","\n","Epoch 00023: acc improved from 0.37650 to 0.37786, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 24/100\n","1953/1953 [==============================] - 725s 371ms/step - loss: 3.0345 - acc: 0.3788\n","\n","Epoch 00024: acc improved from 0.37786 to 0.37879, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 25/100\n","1953/1953 [==============================] - 722s 370ms/step - loss: 3.0277 - acc: 0.3794\n","\n","Epoch 00025: acc improved from 0.37879 to 0.37935, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 26/100\n","1953/1953 [==============================] - 721s 369ms/step - loss: 3.0237 - acc: 0.3804\n","\n","Epoch 00026: acc improved from 0.37935 to 0.38038, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 27/100\n","1953/1953 [==============================] - 722s 370ms/step - loss: 3.0107 - acc: 0.3824\n","\n","Epoch 00027: acc improved from 0.38038 to 0.38243, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 28/100\n","1953/1953 [==============================] - 722s 370ms/step - loss: 3.0104 - acc: 0.3819\n","\n","Epoch 00028: acc did not improve from 0.38243\n","Epoch 29/100\n","1953/1953 [==============================] - 717s 367ms/step - loss: 3.0060 - acc: 0.3827\n","\n","Epoch 00029: acc improved from 0.38243 to 0.38273, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 30/100\n","1953/1953 [==============================] - 715s 366ms/step - loss: 2.9975 - acc: 0.3838\n","\n","Epoch 00030: acc improved from 0.38273 to 0.38377, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 31/100\n","1953/1953 [==============================] - 716s 367ms/step - loss: 2.9865 - acc: 0.3853\n","\n","Epoch 00031: acc improved from 0.38377 to 0.38532, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 32/100\n","1953/1953 [==============================] - 717s 367ms/step - loss: 2.9808 - acc: 0.3862\n","\n","Epoch 00032: acc improved from 0.38532 to 0.38623, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 33/100\n","1953/1953 [==============================] - 717s 367ms/step - loss: 2.9867 - acc: 0.3851\n","\n","Epoch 00033: acc did not improve from 0.38623\n","Epoch 34/100\n","1953/1953 [==============================] - 716s 367ms/step - loss: 2.9700 - acc: 0.3878\n","\n","Epoch 00034: acc improved from 0.38623 to 0.38779, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 35/100\n","1953/1953 [==============================] - 716s 366ms/step - loss: 2.9657 - acc: 0.3874\n","\n","Epoch 00035: acc did not improve from 0.38779\n","Epoch 36/100\n","1953/1953 [==============================] - 720s 369ms/step - loss: 2.9583 - acc: 0.3881\n","\n","Epoch 00036: acc improved from 0.38779 to 0.38814, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 37/100\n","1953/1953 [==============================] - 741s 379ms/step - loss: 2.9569 - acc: 0.3889\n","\n","Epoch 00037: acc improved from 0.38814 to 0.38893, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 38/100\n","1953/1953 [==============================] - 742s 380ms/step - loss: 2.9520 - acc: 0.3893\n","\n","Epoch 00038: acc improved from 0.38893 to 0.38926, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 39/100\n","1953/1953 [==============================] - 742s 380ms/step - loss: 2.9397 - acc: 0.3915\n","\n","Epoch 00039: acc improved from 0.38926 to 0.39151, saving model to drive/My Drive/Machine_Learning-prj/weights-training-improvement-languagemodel.hdf5\n","Epoch 40/100\n","1953/1953 [==============================] - 742s 380ms/step - loss: 3.0480 - acc: 0.3752\n","\n","Epoch 00040: acc did not improve from 0.39151\n","Epoch 41/100\n"," 912/1953 [=============>................] - ETA: 6:35 - loss: 3.2301 - acc: 0.3471"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-a0c88b5bef25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences_digit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences_digit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model.fit_generator(generator=data_generator(sequences_digit, batch_size), steps_per_epoch=(len(sequences_digit)//batch_size) , epochs=100, verbose=1, callbacks=callbacks_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JxN3rIb_dL26"},"outputs":[],"source":["model.save('drive/My Drive/Machine_Learning-prj/vietnamese_language_model/39_weight_language_model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cvSQ0uYmSD9f"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.7 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.7"},"vscode":{"interpreter":{"hash":"d041998d7a86148d723321630367f60f1321ac5570f9aaa1477996cf4f592bf9"}}},"nbformat":4,"nbformat_minor":0}